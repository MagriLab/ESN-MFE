{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective Functions to minimize with Bayesian Optimization\n",
    "\n",
    "# the isnan part is necessary because in the model-informed architecture when the ESN strays\n",
    "# away from the attractor the trajectory may become unbounded\n",
    "\n",
    "\n",
    "def SSV(x):\n",
    "    # Single Shot Validation\n",
    "    \n",
    "    global rho, sigma_in, tikh_opt, k, ti\n",
    "    rho      = 10**x[0]\n",
    "    sigma_in = 10**x[1]\n",
    "    \n",
    "    lenn     = len(tikh)\n",
    "    Mean     = np.zeros(lenn)\n",
    "    \n",
    "    print(ti - time.time())\n",
    "    ti       = time.time()\n",
    "        \n",
    "    #Train\n",
    "    Xa_train, Wout = train(U_washout, U_t, Y_t, tikh, sigma_in, rho)[:2]\n",
    "\n",
    "    for j in range(lenn):\n",
    "            #Validate\n",
    "            Yh_val  = closed_loop(N_val, Xa_train[-1], Wout[j], sigma_in, rho)[0][1:]\n",
    "            kh_val    = 0.5*np.linalg.norm(Yh_val, axis=1)**2\n",
    "            Mean[j] = np.log10(np.mean((kh_val-k_v)**2))\n",
    "\n",
    "            # prevent from diverging to infinity: put MSE equal to 10^10\n",
    "            if np.isnan(Mean[j]) or np.isinf(Mean[j]):\n",
    "                Mean[j] = 10\n",
    "\n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    print(k,Mean, Mean[a])\n",
    "        \n",
    "    return Mean[a]\n",
    "\n",
    "def KFC(x):\n",
    "    # chaotic K-Fold Validation\n",
    "    \n",
    "    global rho, sigma_in, tikh_opt, k, ti\n",
    "    rho      = 10**x[0]\n",
    "    sigma_in = 10**x[1]\n",
    "        \n",
    "    print(ti - time.time())\n",
    "    ti       = time.time()\n",
    "        \n",
    "    lenn     = tikh.size\n",
    "    Mean     = np.zeros(lenn)\n",
    "    \n",
    "    #Train using tv: training+val\n",
    "    Xa_train, Wout, LHS0, RHS0 = train(U_washout, U_tv, Y_tv, tikh, sigma_in, rho)\n",
    "\n",
    "    #Different Folds in the validation set\n",
    "    for i in range(N_fo):\n",
    "\n",
    "        p      = N_in + i*N_fw\n",
    "        k_val  = 0.5*np.linalg.norm(UU[0,N_washout + p : N_washout + p + N_val], axis=1)**2\n",
    "\n",
    "        #Train: remove the validation interval\n",
    "        Xa1    = Xa_train[p+1:p+N_val+1]\n",
    "        Y_t1   = Y_tv[0,p:p+N_val] #Xa_train and Y_tv indices are shifted by one\n",
    "\n",
    "        LHS   = LHS0 - np.dot(Xa1.T, Xa1)\n",
    "        RHS   = RHS0 - np.dot(Xa1.T, Y_t1)\n",
    "        \n",
    "        for j in range(lenn):\n",
    "            Wout[j]  = np.linalg.solve(LHS + tikh[j]*np.eye(N_units+1), RHS)\n",
    "\n",
    "            #Validate\n",
    "            Yh_val    = closed_loop(N_val-1, Xa_train[p], Wout[j], sigma_in, rho)[0]\n",
    "            kh_val    = 0.5*np.linalg.norm(Yh_val, axis=1)**2\n",
    "    \n",
    "            Mean[j]  += np.log10(np.mean((kh_val-k_val)**2))\n",
    "\n",
    "        # prevent from diverging to infinity: put MSE equal to 10^10\n",
    "        if np.isnan(Mean[j]) or np.isinf(Mean[j]):\n",
    "            Mean[j] = 10*N_fo\n",
    "                \n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    print(k,Mean/N_fo, Mean[a]/N_fo)\n",
    "\n",
    "    return Mean[a]/N_fo\n",
    "\n",
    "\n",
    "def RVC(x):\n",
    "    # chaotic Recycle Validation\n",
    "    \n",
    "    global rho, sigma_in, tikh_opt, k, ti\n",
    "    rho      = 10**x[0]\n",
    "    sigma_in = 10**x[1]\n",
    "        \n",
    "    print(ti - time.time())\n",
    "    ti       = time.time()\n",
    "        \n",
    "    lenn     = tikh.size\n",
    "    Mean     = np.zeros(lenn)\n",
    "    \n",
    "    #Train using tv: training+val\n",
    "    Xa_train, Wout, LHS0, RHS0 = train(U_washout, U_tv, Y_tv, tikh, sigma_in, rho)\n",
    "\n",
    "    #Different Folds in the validation set\n",
    "    for i in range(N_fo):\n",
    "\n",
    "        p      = N_in + i*N_fw\n",
    "        k_val  = 0.5*np.linalg.norm(UU[0,N_washout + p : N_washout + p + N_val], axis=1)**2\n",
    "\n",
    "#         #Train: remove the validation interval\n",
    "#         Xa1    = Xa_train[p+1:p+N_val+1]\n",
    "#         Y_t1   = Y_tv[p:p+N_val] #Xa_train and Y_tv indices are shifted by one\n",
    "\n",
    "#         LHS   = LHS0 - np.dot(Xa1.T, Xa1)\n",
    "#         RHS   = RHS0 - np.dot(Xa1.T, Y_t1)\n",
    "        \n",
    "        for j in range(lenn):\n",
    "#             Wout[j]  = np.linalg.solve(LHS + tikh[j]*np.eye(N_units+1), RHS)\n",
    "\n",
    "            #Validate\n",
    "            Yh_val    = closed_loop(N_val-1, Xa_train[p], Wout[j], sigma_in, rho)[0]\n",
    "            kh_val    = 0.5*np.linalg.norm(Yh_val, axis=1)**2\n",
    "    \n",
    "            Mean[j]  += np.log10(np.mean((kh_val-k_val)**2))\n",
    "\n",
    "        # prevent from diverging to infinity: put MSE equal to 10^10\n",
    "        if np.isnan(Mean[j]) or np.isinf(Mean[j]):\n",
    "            Mean[j] = 10*N_fo\n",
    "                \n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    print(k,Mean/N_fo, Mean[a]/N_fo)\n",
    "\n",
    "    return Mean[a]/N_fo   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Val_PI(x):\n",
    "    # Single Shot Validation\n",
    "    \n",
    "    global rho, sigma_in, tikh_opt, k, ti\n",
    "    \n",
    "    rho      = 10**x[0]\n",
    "    sigma_in = 10**x[1]\n",
    "    \n",
    "    lenn     = len(tikh)\n",
    "    Mean     = np.zeros(lenn)\n",
    "    \n",
    "    print(ti - time.time())\n",
    "    ti       = time.time()\n",
    "        \n",
    "    #Train\n",
    "    Xa_train, Wout = train(U_washout, U_tv, Y_tv, tikh, sigma_in, rho)[:2]\n",
    "\n",
    "    for j in range(lenn):\n",
    "            #Validate\n",
    "            Yh_val  = closed_loop(N_valPI, Xa_train[-1], Wout[j], sigma_in, rho)[0][1:]\n",
    "            fh_val  = MFE(Yh_val)[:-1]\n",
    "            dyh_val = (Yh_val[1:] - Yh_val[:-1])/dt\n",
    "            Mean[j] = np.log10(np.mean((fh_val-dyh_val)**2))\n",
    "            \n",
    "            if Mean[j] < -3:\n",
    "                plt.subplots(2,1)\n",
    "                plt.subplot(211)\n",
    "                plt.plot(Yh_val)\n",
    "                print(0.5*np.linalg.norm(Yh_val[-1])**2)\n",
    "                plt.subplot(212)\n",
    "                plt.plot(MFE(Yh_val))\n",
    "                plt.show()\n",
    "\n",
    "            # prevent from diverging to infinity: put MSE equal to 10^10\n",
    "            if np.isnan(Mean[j]) or np.isinf(Mean[j]):\n",
    "                Mean[j] = 10\n",
    "\n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    print(k,Mean, Mean[a])\n",
    "        \n",
    "    return Mean[a]\n",
    "\n",
    "def RVC_PI(x):\n",
    "    # chaotic Recycle Validation\n",
    "    \n",
    "    global rho, sigma_in, tikh_opt, k, ti\n",
    "    rho      = 10**x[0]\n",
    "    sigma_in = 10**x[1]\n",
    "        \n",
    "    print(ti - time.time())\n",
    "    ti       = time.time()\n",
    "        \n",
    "    lenn     = tikh.size\n",
    "    Mean     = np.zeros(lenn)\n",
    "    \n",
    "    #Train using tv: training+val\n",
    "    Xa_train, Wout, LHS0, RHS0 = train(U_washout, U_tv, Y_tv, tikh, sigma_in, rho)\n",
    "\n",
    "    #Different Folds in the validation set\n",
    "    for i in range(N_fo):\n",
    "\n",
    "        p      = N_in + i*N_fw\n",
    "#         k_val  = 0.5*np.linalg.norm(UU[0,N_washout + p : N_washout + p + N_val], axis=1)**2\n",
    "\n",
    "#         #Train: remove the validation interval\n",
    "#         Xa1    = Xa_train[p+1:p+N_val+1]\n",
    "#         Y_t1   = Y_tv[p:p+N_val] #Xa_train and Y_tv indices are shifted by one\n",
    "\n",
    "#         LHS   = LHS0 - np.dot(Xa1.T, Xa1)\n",
    "#         RHS   = RHS0 - np.dot(Xa1.T, Y_t1)\n",
    "        \n",
    "        for j in range(lenn):\n",
    "#             Wout[j]  = np.linalg.solve(LHS + tikh[j]*np.eye(N_units+1), RHS)\n",
    "\n",
    "            #Validate\n",
    "            Yh_val    = closed_loop(N_valPI, Xa_train[p], Wout[j], sigma_in, rho)[0]\n",
    "            fh_val    = MFE(Yh_val)[:-1]\n",
    "            dyh_val   = (Yh_val[1:] - Yh_val[:-1])/dt\n",
    "            Mean[j]  += np.log10(np.mean((fh_val-dyh_val)**2))\n",
    "\n",
    "        # prevent from diverging to infinity: put MSE equal to 10^10\n",
    "        if np.isnan(Mean[j]) or np.isinf(Mean[j]):\n",
    "            Mean[j] = 10*N_fo\n",
    "                \n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    print(k,Mean/N_fo, Mean[a]/N_fo)\n",
    "\n",
    "    return Mean[a]/N_fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFE(q):\n",
    "    \"\"\"\n",
    "    Defines the differential equations for Moehlis_2004\n",
    "\n",
    "    Arguments:\n",
    "        w :  vector of the state variables a_i\n",
    "    \"\"\"\n",
    "\n",
    "    Ndim = 9\n",
    "    # Problem Definition\n",
    "    Lx = 4*math.pi\n",
    "    Ly = 2.\n",
    "    Lz = 2*math.pi\n",
    "    Re = 400\n",
    "    # Parameter values\n",
    "    alfa  = 2*math.pi/Lx\n",
    "    beta  = math.pi/2\n",
    "    gamma = 2*math.pi/Lz\n",
    "\n",
    "    k1 = np.sqrt(alfa**2 + gamma**2)\n",
    "    k2 = np.sqrt(gamma**2 + beta**2)\n",
    "    k3 = np.sqrt(alfa**2 + beta**2 + gamma**2) \n",
    "    \n",
    "    a1, a2, a3, a4, a5, a6, a7, a8, a9 = q.T\n",
    "    \n",
    "    aa1 = beta**2/Re * (1. - a1) - np.sqrt(3/2)*beta*gamma/k3*np.multiply(a6,a8) + \\\n",
    "            np.sqrt(3/2)*beta*gamma/k2*np.multiply(a2,a3)\n",
    "\n",
    "    aa2 = - ( 4/3*beta**2 + gamma**2) * a2/Re + 5/3*np.sqrt(2/3)*gamma**2/k1*np.multiply(a4,a6) - \\\n",
    "          gamma**2/np.sqrt(6)/k1*np.multiply(a5,a7) - \\\n",
    "          alfa*gamma*beta/np.sqrt(6)/k1/k3*np.multiply(a5,a8) - \\\n",
    "          np.sqrt(3/2)*beta*gamma/k2 * (np.multiply(a1,a3) + np.multiply(a3,a9))\n",
    "\n",
    "    aa3 = - (beta**2 + gamma**2)/Re*a3 + 2/np.sqrt(6)*alfa*beta*gamma/k1/k2 * (np.multiply(a4,a7) + \\\n",
    "          np.multiply(a5,a6)) + \\\n",
    "          (beta**2*(3*alfa**2+gamma**2) - 3*gamma**2*(alfa**2+gamma**2))/np.sqrt(6)/k1/k2/k3*np.multiply(a4,a8)\n",
    "\n",
    "    aa4 = - (3*alfa**2 + 4*beta**2)/3/Re*a4 - alfa/np.sqrt(6)*np.multiply(a1,a5) - \\\n",
    "         10/3/np.sqrt(6)*alfa**2/k1*np.multiply(a2,a6) - \\\n",
    "         np.sqrt(3/2)*alfa*beta*gamma/k1/k2*np.multiply(a3,a7) - \\\n",
    "         np.sqrt(3/2)*alfa**2*beta**2/k1/k2/k3*np.multiply(a3,a8) - \\\n",
    "         alfa/np.sqrt(6)*np.multiply(a5,a9)\n",
    "\n",
    "    aa5 = - (alfa**2 + beta**2)/Re*a5 + alfa/np.sqrt(6)*np.multiply(a1,a4) + \\\n",
    "         alfa**2/np.sqrt(6)/k1*np.multiply(a2,a7) - \\\n",
    "         alfa*beta*gamma/np.sqrt(6)/k1/k3*np.multiply(a2,a8) + \\\n",
    "         alfa/np.sqrt(6)*np.multiply(a4,a9) + \\\n",
    "         2/np.sqrt(6)*alfa*beta*gamma/k1/k2*np.multiply(a3,a6)\n",
    "\n",
    "    aa6 = - (3*alfa**2 + 4*beta**2 + 3*gamma**2)/3/Re*a6 + alfa/np.sqrt(6)*np.multiply(a1,a7) + \\\n",
    "         np.sqrt(3/2)*beta*gamma/k3*np.multiply(a1,a8) + \\\n",
    "         10/3/np.sqrt(6)*(alfa**2 - gamma**2)/k1*np.multiply(a2,a4) - \\\n",
    "         2*np.sqrt(2/3)*alfa*beta*gamma/k1/k2*np.multiply(a3,a5) + \\\n",
    "         alfa/np.sqrt(6)*np.multiply(a7,a9) + np.sqrt(3/2)*beta*gamma/k3*np.multiply(a8,a9)\n",
    "\n",
    "    aa7 = - k3**2/Re*a7 - alfa/np.sqrt(6) * (np.multiply(a1,a6) + np.multiply(a6,a9)) + \\\n",
    "         (gamma**2 - alfa**2)/np.sqrt(6)/k1*np.multiply(a2,a5) + \\\n",
    "          alfa*beta*gamma/np.sqrt(6)/k1/k2*np.multiply(a3,a4)\n",
    "\n",
    "    aa8 = - k3**2/Re*a8 + 2/np.sqrt(6)*alfa*beta*gamma/k3/k1*np.multiply(a2,a5) + \\\n",
    "         gamma**2*(3*alfa**2 - beta**2 + 3*gamma**2)/np.sqrt(6)/k1/k2/k3*np.multiply(a3,a4)\n",
    "    \n",
    "    aa9 = - 9*beta**2/Re*a9 + np.sqrt(3/2)*beta*gamma/k2*np.multiply(a2,a3) - \\\n",
    "         np.sqrt(3/2)*beta*gamma/k3*np.multiply(a6,a8)\n",
    "    \n",
    "    return np.stack([aa1,aa2,aa3,aa4,aa5,aa6,aa7,aa8,aa9],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFC_Phys(x):\n",
    "    # chaotic K-Fold Validation\n",
    "    \n",
    "    global rho, sigma_in, tikh_opt, k\n",
    "    rho      = x[0]\n",
    "    sigma_in = x[1]\n",
    "    \n",
    "    lenn     = len(tikh)\n",
    "    \n",
    "    Mean     = np.zeros(lenn)\n",
    "     \n",
    "    #Train using tv: training+val\n",
    "    Xa_train, Wout, LHS0, RHS0 = train(U_washout, U_tv, Y_tv, tikh)\n",
    "\n",
    "    #Different Folds in the validation set\n",
    "    for i in range(N_fo):\n",
    "\n",
    "        p      = N_in + i*N_fw\n",
    "\n",
    "        #Train: remove the validation interval\n",
    "        Xa1    = Xa_train[p+1:p+N_val+1]\n",
    "        Y_t1   = Y_tv[p:p+N_val] #Xa_train and Y_tv indices are shifted by one\n",
    "\n",
    "        LHS   = LHS0 - np.dot(Xa1.T, Xa1)\n",
    "        RHS   = RHS0 - np.dot(Xa1.T, Y_t1)\n",
    "        \n",
    "        for j in range(lenn):\n",
    "            Wout[j]  = np.linalg.solve(LHS + tikh[j]*np.eye(N_units+1), RHS)\n",
    "\n",
    "            #Validate\n",
    "            Yh_val = closed_loop(N_phys, Xa_train[p], Wout[j])[0]\n",
    "            dy_dt  = (Yh_val[1:] - Yh_val[:-1])/dt\n",
    "            fy     = MFE(Yh_val[:-1])\n",
    "            Mean[j]  += np.log10(np.mean((dy_dt - fy)**2))\n",
    "\n",
    "        # prevent from diverging to infinity: put MSE equal to 10^10\n",
    "        if np.isnan(Mean[j]) or np.isinf(Mean[j]):\n",
    "            Mean[j] = 10*N_fo\n",
    "    \n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    print(k,Mean/N_fo, Mean[a]/N_fo)\n",
    "\n",
    "    return Mean[a]/N_fo\n",
    "\n",
    "def KFC_MI(x):\n",
    "    # chaotic K-Fold Validation\n",
    "    \n",
    "    global rho, sigma_in, tikh_opt, k\n",
    "    rho      = x[0]\n",
    "    sigma_in = x[1]\n",
    "    \n",
    "    lenn     = len(tikh)\n",
    "    \n",
    "    Mean     = np.zeros(lenn)\n",
    "     \n",
    "    #Train using tv: training+val\n",
    "    Xa_train, Wout, LHS0, RHS0 = train(U_washout, U_tv, Y_tv, tikh)\n",
    "\n",
    "    N_fo = 96  # number of folds\n",
    "    N_in = 0   # interval before the first fold\n",
    "    N_fw = N_lyap # how many steps forward the validation interval is shifted \n",
    "\n",
    "    #Different Folds in the validation set\n",
    "    for i in range(N_fo):\n",
    "\n",
    "        p      = N_in + i*N_fw\n",
    "        Y_val  = U[N_washout + p : N_washout + p + N_val]\n",
    "\n",
    "        #Train: remove the validation interval\n",
    "        Xa1    = Xa_train[p+1:p+N_val+1]\n",
    "        Y_t1   = Y_tv[p:p+N_val] #Xa_train and Y_tv indices are shifted by one\n",
    "\n",
    "        LHS   = LHS0 - np.dot(Xa1.T, Xa1)\n",
    "        RHS   = RHS0 - np.dot(Xa1.T, Y_t1)\n",
    "        \n",
    "        for j in range(lenn):\n",
    "            Wout[j]  = np.linalg.solve(LHS + tikh[j]*np.eye(N_units+NPOD+1), RHS)\n",
    "\n",
    "            #Validate\n",
    "            Yh_val = closed_loop(N_val-1, Xa_train[p], Wout[j])[0]\n",
    "#             Mean[j]  += np.mean((Yh_val-Y_val)**2)\n",
    "            Mean[j]  += np.log10(np.mean((Yh_val-Y_val)**2))\n",
    "\n",
    "        # prevent from diverging to infinity: put MSE equal to 10^10\n",
    "        if np.isnan(Mean[j]) or np.isinf(Mean[j]):\n",
    "            Mean[j] = 10*N_fo\n",
    "    \n",
    "    a           = np.argmin(Mean)\n",
    "    tikh_opt[k] = tikh[a]\n",
    "    k          +=1\n",
    "    print(k,Mean/N_fo, Mean[a]/N_fo)\n",
    "\n",
    "    return Mean[a]/N_fo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
