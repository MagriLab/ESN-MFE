{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODE Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_euler(ddt, u0, T, *args):\n",
    "    u = np.empty((T.size, u0.size))\n",
    "    u[0] = u0\n",
    "    for i in range(1, T.size):\n",
    "        u[i] = u[i-1] + (T[i] - T[i-1]) * ddt(u[i-1], T[i-1], *args)\n",
    "    return u\n",
    "\n",
    "def ddt(u, t, params):\n",
    "    beta, rho, sigma = params\n",
    "    x, y, z = u\n",
    "    return np.array([sigma*(y-x), x*(rho-z)-y, x*y-beta*z])\n",
    "\n",
    "def solve_ode(N, dt, u0, params=[8/3, 28, 10]):\n",
    "    \"\"\"\n",
    "        Solves the ODEs for N time steps starting from u0.\n",
    "        Returned values are normalized.\n",
    "\n",
    "        Args:\n",
    "            N: number of time steps\n",
    "            u0: initial condition\n",
    "            norm: normalisation factor of u0 (None if not normalised)\n",
    "            params: parameters for ODE\n",
    "        Returns:\n",
    "            normalized time series of shape (N+1, u0.size)\n",
    "    \"\"\"\n",
    "\n",
    "    T = np.arange(N+1) * dt\n",
    "    U = forward_euler(ddt, u0, T, params)\n",
    "\n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESN with bias architecture\n",
    "\n",
    "def step(x_pre, u, sigma_in, rho):\n",
    "    \"\"\" Advances one ESN time step.\n",
    "        Args:\n",
    "            x_pre: reservoir state\n",
    "            u: input\n",
    "        Returns:\n",
    "            new augmented state (new state with bias_out appended)\n",
    "    \"\"\"\n",
    "    # input is normalized and input bias added\n",
    "    u_augmented = np.hstack((u/norm, np.array([bias_in]))) \n",
    "    # hyperparameters are explicit here\n",
    "    x_post      = np.tanh(np.dot(u_augmented*sigma_in, Win) + rho*np.dot(x_pre, W)) \n",
    "    # output bias added\n",
    "    x_augmented = np.hstack((x_post, np.array([bias_out])))\n",
    "\n",
    "    return x_augmented\n",
    "\n",
    "# @njit(parallel=False)\n",
    "def open_loop(U, x0, sigma_in, rho):\n",
    "    \"\"\" Advances ESN in open-loop.\n",
    "        Args:\n",
    "            U: input time series\n",
    "            x0: initial reservoir state\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "    \"\"\"\n",
    "    N  = U.shape[0]\n",
    "    Xa = np.empty((N+1, N_units+1))\n",
    "    Xa[0] = np.hstack((x0, np.array([bias_out])))\n",
    "    for i in np.arange(1,N+1):\n",
    "        Xa[i] = step(Xa[i-1,:N_units], U[i-1], sigma_in, rho)\n",
    "\n",
    "    return Xa\n",
    "\n",
    "# @njit(parallel=False)\n",
    "def closed_loop(N, x0, Wout, sigma_in, rho):\n",
    "    \"\"\" Advances ESN in closed-loop.\n",
    "        Args:\n",
    "            N: number of time steps\n",
    "            x0: initial reservoir state\n",
    "            Wout: output matrix\n",
    "        Returns:\n",
    "            time series of prediction\n",
    "            final augmented reservoir state\n",
    "    \"\"\"\n",
    "    xa = x0.copy()\n",
    "    Yh = np.empty((N+1, dim))\n",
    "    Yh[0] = np.dot(xa, Wout)\n",
    "    for i in np.arange(1,N+1):\n",
    "        xa = step(xa[:N_units], Yh[i-1], sigma_in, rho)\n",
    "        Yh[i] = np.dot(xa, Wout)\n",
    "\n",
    "    return Yh, xa\n",
    "\n",
    "def train(U_washout, U_train, Y_train, tikh, sigma_in, rho):\n",
    "    \"\"\" Trains ESN.\n",
    "        Args:\n",
    "            U_washout: washout input time series\n",
    "            U_train: training input time series\n",
    "            tikh: Tikhonov factor\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "            optimal output matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    LHS = 0\n",
    "    RHS = 0\n",
    "    \n",
    "    N  = U_train[0].shape[0]    \n",
    "    Xa  = np.zeros((U_washout.shape[0], N+1, N_units+1))\n",
    "    \n",
    "    for i in range(U_washout.shape[0]):\n",
    "        \n",
    "        ## washout phase\n",
    "        xf_washout = open_loop(U_washout[i], np.zeros(N_units), sigma_in, rho)[-1,:N_units]\n",
    "\n",
    "        ## open-loop train phase\n",
    "        Xa[i] = open_loop(U_train[i], xf_washout, sigma_in, rho)\n",
    "    \n",
    "        ## Ridge Regression\n",
    "        LHS  += np.dot(Xa[i,1:].T, Xa[i,1:])\n",
    "        RHS  += np.dot(Xa[i,1:].T, Y_train[i])\n",
    "    \n",
    "    Wout = np.linalg.solve(LHS + tikh*np.eye(N_units+1), RHS)\n",
    "\n",
    "    return Xa[0], Wout, LHS, RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictability_horizon(xa, Y, Wout):\n",
    "    \"\"\" Compute predictability horizon. It evolves the network until the\n",
    "        error is greater than the threshold. Before that it initialises\n",
    "        the network by running a washout phase.\n",
    "        \n",
    "        Args:\n",
    "            threshold: error threshold\n",
    "            U_washout: time series for washout\n",
    "            Y: time series to compare prediction\n",
    "        \n",
    "        Returns:\n",
    "            predictability horizon (in time units, not Lyapunov times)\n",
    "            time series of normalised error\n",
    "            time series of prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate denominator of the normalised error\n",
    "    kin   = 0.5*np.linalg.norm(Y, axis=1)**2\n",
    "#     err_z = np.sqrt(np.mean(kin**2))\n",
    "    err_d = np.mean(np.sum((Y[:,:dim])**2, axis=1))\n",
    "    \n",
    "    N     = Y.shape[0]\n",
    "    E     = np.zeros(N+1)\n",
    "    E_z   = np.zeros(N+1)\n",
    "    Yh    = np.zeros((N, len(idx1)))\n",
    "    kinh  = np.zeros(N)\n",
    "    \n",
    "    Yh[0]   = np.dot(xa, Wout)\n",
    "    kinh[0] =0.5*np.linalg.norm(Yh[0])**2\n",
    "    \n",
    "    pr_idx = np.zeros(N)\n",
    "    pr_idd = np.zeros(N)\n",
    "    \n",
    "    pr_idx[-1] = 1\n",
    "    pr_idd[-1] = 1\n",
    "    \n",
    "    for i in range(1, N):\n",
    "        # advance one step\n",
    "        xa       = step(xa[:N_units], Yh[i-1][:dim])\n",
    "        Yh[i]    = np.dot(xa, Wout)\n",
    "        kinh[i]  = 0.5*np.linalg.norm(Yh[i])**2\n",
    "    \n",
    "        # calculate error\n",
    "        E_z[i]  = np.abs(kinh[i]-kin[i])\n",
    "        err_n   = np.sum(((Yh[i,:dim]-Y[i,:dim]))**2)\n",
    "        E[i]    = np.sqrt(err_n/err_d)\n",
    "\n",
    "        if E_z[i] > threshold:\n",
    "            break\n",
    "        \n",
    "        if E_z[i] > tt:\n",
    "            pr_idx[i] = 1\n",
    "            \n",
    "        if E[i]   > 0.2:\n",
    "            pr_idd[i] = 1\n",
    "    \n",
    "    a = np.nonzero(pr_idx)[0][0]/N_lyap\n",
    "    b = np.nonzero(pr_idd)[0][0]/N_lyap\n",
    "\n",
    "    t = np.arange(i)/N_lyap\n",
    "#     fig, ax1 = plt.subplots(1,2)\n",
    "    \n",
    "#     ax=plt.subplot(1,2,1)\n",
    "#     plt.annotate('{:.2f}'.format(a), xy=(0, 1), xytext=(5, -5), va='top', ha='left',\n",
    "#              xycoords='axes fraction', textcoords='offset points')\n",
    "#     plt.ylim(1e-4,threshold)\n",
    "#     plt.axhline(.2)\n",
    "#     ax.set_ylabel('$E$')\n",
    "#     plt.plot(t,E_z[:i], label='$E_k$')\n",
    "#     plt.plot(t,E[:i], label='$E$')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     ax = plt.subplot(1,2,2)\n",
    "#     ax.set_ylabel('$k$')\n",
    "    if is_plot:\n",
    "        plt.axhline(ee,linewidth=3, alpha=0.3)\n",
    "        plt.axvline(a,linewidth=3, alpha=0.3)\n",
    "        plt.plot(t,kin[:i], label='True')\n",
    "        plt.plot(t,kinh[:i], label='ESN')\n",
    "        plt.legend(fontsize=20)\n",
    "        plt.show()\n",
    "            \n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictability_horizon_k(xa, Y, Wout, sigma_in, rho):\n",
    "    \"\"\" Compute predictability horizon. It evolves the network until the\n",
    "        error is greater than the threshold. Before that it initialises\n",
    "        the network by running a washout phase.\n",
    "        \n",
    "        Args:\n",
    "            threshold: error threshold\n",
    "            U_washout: time series for washout\n",
    "            Y: time series to compare prediction\n",
    "        \n",
    "        Returns:\n",
    "            predictability horizon (in time units, not Lyapunov times)\n",
    "            time series of normalised error\n",
    "            time series of prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate denominator of the normalised error\n",
    "    kin   = 0.5*np.linalg.norm(Y, axis=1)**2\n",
    "    \n",
    "    N     = Y.shape[0]\n",
    "    E     = np.zeros(N+1)\n",
    "    Yh    = np.zeros((N, len(idx1)))\n",
    "    kinh  = np.zeros(N)\n",
    "    \n",
    "    Yh[0]   = np.dot(xa, Wout)\n",
    "    kinh[0] = 0.5*np.linalg.norm(Yh[0])**2\n",
    "    \n",
    "    pr_idx = np.zeros(N)\n",
    "    pr_idd = np.zeros(N)\n",
    "    \n",
    "    pr_idx[-1] = 1\n",
    "    pr_idd[-1] = 1\n",
    "    \n",
    "    for i in range(1, N):\n",
    "        # advance one step\n",
    "        xa       = step(xa[:N_units], Yh[i-1][:dim], sigma_in, rho)\n",
    "        Yh[i]    = np.dot(xa, Wout)\n",
    "        kinh[i]  = 0.5*np.linalg.norm(Yh[i])**2\n",
    "    \n",
    "        # calculate error\n",
    "        E[i]  = np.abs(kinh[i]-kin[i])\n",
    "            \n",
    "        if E[i] > threshold:\n",
    "            break\n",
    "#             pr_idd[i] = 1\n",
    "    \n",
    "#     a = np.nonzero(pr_idx)[0][0]/N_lyap\n",
    "#     b = np.nonzero(pr_idd)[0][0]/N_lyap\n",
    "\n",
    "#     t = np.arange(i)/N_lyap\n",
    "#     fig, ax1 = plt.subplots(1,2)\n",
    "    \n",
    "#     ax=plt.subplot(1,2,1)\n",
    "#     plt.annotate('{:.2f}'.format(a), xy=(0, 1), xytext=(5, -5), va='top', ha='left',\n",
    "#              xycoords='axes fraction', textcoords='offset points')\n",
    "#     plt.ylim(1e-4,threshold)\n",
    "#     plt.axhline(.2)\n",
    "#     ax.set_ylabel('$E$')\n",
    "#     plt.plot(t,E_z[:i], label='$E_k$')\n",
    "#     plt.plot(t,E[:i], label='$E$')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     ax = plt.subplot(1,2,2)\n",
    "#     ax.set_ylabel('$k$')\n",
    "#     if is_plot:\n",
    "#         plt.axhline(ee,linewidth=3, alpha=0.3)\n",
    "#         plt.axvline(a,linewidth=3, alpha=0.3)\n",
    "#         plt.plot(t,kin[:i], label='True')\n",
    "#         plt.plot(t,kinh[:i], label='ESN')\n",
    "#         plt.legend(fontsize=20)\n",
    "#         plt.show()\n",
    "            \n",
    "    return i/N_lyap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFE_modes(X):\n",
    "    \n",
    "    Ndim = 9\n",
    "    # Problem Definition\n",
    "    Lx = 4*math.pi\n",
    "    Ly = 2.\n",
    "    Lz = 2*math.pi\n",
    "    Re = 400\n",
    "    # Parameter values\n",
    "    alfa  = 2*math.pi/Lx\n",
    "    beta  = math.pi/2\n",
    "    gamma = 2*math.pi/Lz\n",
    "\n",
    "    pi       = math.pi\n",
    "    cos      = np.cos\n",
    "    sin      = np.sin\n",
    "\n",
    "    x, y, z  = X\n",
    "\n",
    "    k1 = np.sqrt(alfa**2 + gamma**2)\n",
    "    k2 = np.sqrt(gamma**2 + beta**2)\n",
    "    k3 = np.sqrt(alfa**2 + beta**2 + gamma**2) \n",
    "    \n",
    "    # a1, a2, a3, a4, a5, a6, a7, a8, a9 = q.T \n",
    "    \n",
    "    m1  = np.array([np.sqrt(2)*sin(pi*y/2), 0*x, 0*x])\n",
    "\n",
    "    m2  = np.array([4/np.sqrt(3)*cos(pi*y/2)**2*cos(gamma*z), 0*x, 0*x]) \n",
    "\n",
    "    m3  = 2/np.sqrt(4*gamma**2+pi**2)*np.array(\n",
    "         [0*x, 2*gamma*cos(pi*y/2)*cos(gamma*z), pi*sin(pi*y/2)*sin(gamma*z)]) \n",
    "\n",
    "    m4  = np.array([0*x, 0*x, 4/np.sqrt(3)*cos(alfa*x)*cos(pi*y/2)**2]) \n",
    "\n",
    "    m5  = np.array([0*x, 0*x, 2*sin(alfa*x)*sin(pi*y/2)])\n",
    "\n",
    "    m6  = 4*np.sqrt(2)/np.sqrt(3*(gamma**2+alfa**2))*np.array(\n",
    "        [-gamma*cos(math.pi*y/2)**2*cos(alfa*x)*sin(gamma*z), 0*x,\n",
    "          alfa*cos(math.pi*y/2)**2*sin(alfa*x)*cos(gamma*z)]) \n",
    "\n",
    "    m7  = 2*np.sqrt(2)/np.sqrt(gamma**2+alfa**2)*np.array(\n",
    "        [ gamma*sin(math.pi*y/2)*sin(alfa*x)*sin(gamma*z), 0*x,\n",
    "          alfa*sin(math.pi*y/2)*cos(alfa*x)*cos(gamma*z)])\n",
    "\n",
    "    N8  = 2*np.sqrt(2)/np.sqrt((gamma**2+alfa**2)*(4*alfa**2+4*gamma**2+pi**2))\n",
    "\n",
    "    m8  = N8*np.array([pi*alfa*sin(math.pi*y/2)*sin(alfa*x)*sin(gamma*z), \n",
    "                       2*(gamma**2+alfa**2)*cos(math.pi*y/2)*cos(alfa*x)*sin(gamma*z),\n",
    "                       -pi*gamma*sin(math.pi*y/2)*cos(alfa*x)*cos(gamma*z)]) \n",
    "\n",
    "    m9  = np.array([np.sqrt(2)*sin(3*math.pi*y/2), 0*x, 0*x])\n",
    "    \n",
    "    return np.stack([m1,m2,m3,m4,m5,m6,m7,m8,m9],axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
