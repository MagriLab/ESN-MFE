{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODE Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_euler(ddt, u0, T, *args):\n",
    "    u = np.empty((T.size, u0.size))\n",
    "    u[0] = u0\n",
    "    for i in range(1, T.size):\n",
    "        u[i] = u[i-1] + (T[i] - T[i-1]) * ddt(u[i-1], T[i-1], *args)\n",
    "    return u\n",
    "\n",
    "def ddt(u, t, params):\n",
    "    beta, rho, sigma = params\n",
    "    x, y, z = u\n",
    "    return np.array([sigma*(y-x), x*(rho-z)-y, x*y-beta*z])\n",
    "\n",
    "def solve_ode(N, dt, u0, params=[8/3, 28, 10]):\n",
    "    \"\"\"\n",
    "        Solves the ODEs for N time steps starting from u0.\n",
    "        Returned values are normalized.\n",
    "\n",
    "        Args:\n",
    "            N: number of time steps\n",
    "            u0: initial condition\n",
    "            norm: normalisation factor of u0 (None if not normalised)\n",
    "            params: parameters for ODE\n",
    "        Returns:\n",
    "            normalized time series of shape (N+1, u0.size)\n",
    "    \"\"\"\n",
    "\n",
    "    T = np.arange(N+1) * dt\n",
    "    U = forward_euler(ddt, u0, T, params)\n",
    "\n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESN with bias architecture\n",
    "\n",
    "# @njit(parallel=False)\n",
    "def step(x_pre, u, sigma_in, rho):\n",
    "    \"\"\" Advances one ESN time step.\n",
    "        Args:\n",
    "            x_pre: reservoir state\n",
    "            u: input\n",
    "        Returns:\n",
    "            new augmented state (new state with bias_out appended)\n",
    "    \"\"\"\n",
    "    # input is normalized and input bias added\n",
    "    u_augmented = np.hstack((u/norm, np.array([bias_in]))) \n",
    "    # hyperparameters are explicit here\n",
    "    x_post      = np.tanh(np.dot(u_augmented*sigma_in, Win) + rho*np.dot(x_pre, W)) \n",
    "    # output bias added\n",
    "    x_augmented = np.hstack((x_post, np.array([bias_out])))\n",
    "\n",
    "    return x_augmented\n",
    "\n",
    "# @njit(parallel=False)\n",
    "def open_loop(U, x0, sigma_in, rho):\n",
    "    \"\"\" Advances ESN in open-loop.\n",
    "        Args:\n",
    "            U: input time series\n",
    "            x0: initial reservoir state\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "    \"\"\"\n",
    "    N  = U.shape[0]\n",
    "    Xa = np.empty((N+1, N_units+1))\n",
    "    Xa[0] = np.hstack((x0, np.array([bias_out])))\n",
    "    for i in np.arange(1,N+1):\n",
    "        Xa[i] = step(Xa[i-1,:N_units], U[i-1], sigma_in, rho)\n",
    "\n",
    "    return Xa\n",
    "\n",
    "# @njit(parallel=False)\n",
    "def closed_loop(N, x0, Wout, sigma_in, rho):\n",
    "    \"\"\" Advances ESN in closed-loop.\n",
    "        Args:\n",
    "            N: number of time steps\n",
    "            x0: initial reservoir state\n",
    "            Wout: output matrix\n",
    "        Returns:\n",
    "            time series of prediction\n",
    "            final augmented reservoir state\n",
    "    \"\"\"\n",
    "    xa = x0.copy()\n",
    "    Yh = np.empty((N+1, dim))\n",
    "    Yh[0] = np.dot(xa, Wout)\n",
    "    for i in np.arange(1,N+1):\n",
    "        xa = step(xa[:N_units], Yh[i-1], sigma_in, rho)\n",
    "        Yh[i] = np.dot(xa, Wout)\n",
    "\n",
    "    return Yh, xa\n",
    "\n",
    "# @njit(parallel=False)\n",
    "def train(U_washout, U_train, Y_train, tikh, sigma_in, rho):\n",
    "    \"\"\" Trains ESN.\n",
    "        Args:\n",
    "            U_washout: washout input time series\n",
    "            U_train: training input time series\n",
    "            tikh: Tikhonov factor\n",
    "        Returns:\n",
    "            time series of augmented reservoir states\n",
    "            optimal output matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    LHS = 0\n",
    "    RHS = 0\n",
    "    \n",
    "    N  = U_train[0].shape[0]    \n",
    "    Xa  = np.zeros((U_washout.shape[0], N+1, N_units+1))\n",
    "    \n",
    "    for i in range(U_washout.shape[0]):\n",
    "        \n",
    "        ## washout phase\n",
    "        xf_washout = open_loop(U_washout[i], np.zeros(N_units), sigma_in, rho)[-1,:N_units]\n",
    "\n",
    "        ## open-loop train phase\n",
    "        Xa[i] = open_loop(U_train[i], xf_washout, sigma_in, rho)\n",
    "    \n",
    "        ## Ridge Regression\n",
    "        LHS  += np.dot(Xa[i,1:].T, Xa[i,1:])\n",
    "        RHS  += np.dot(Xa[i,1:].T, Y_train[i])\n",
    "    \n",
    "    Wout = np.zeros((tikh.size, N_units+1,dim))\n",
    "    for j in np.arange(tikh.size):\n",
    "        Wout[j] = np.linalg.solve(LHS + tikh[j]*np.eye(N_units+1), RHS)\n",
    "\n",
    "    return Xa[0], Wout, LHS, RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictability_horizon(xa, Y, Wout):\n",
    "    \"\"\" Compute predictability horizon. It evolves the network until the\n",
    "        error is greater than the threshold. Before that it initialises\n",
    "        the network by running a washout phase.\n",
    "        \n",
    "        Args:\n",
    "            threshold: error threshold\n",
    "            U_washout: time series for washout\n",
    "            Y: time series to compare prediction\n",
    "        \n",
    "        Returns:\n",
    "            predictability horizon (in time units, not Lyapunov times)\n",
    "            time series of normalised error\n",
    "            time series of prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate denominator of the normalised error\n",
    "    error_denominator = np.mean(np.sum((Y)**2, axis=1))\n",
    "\n",
    "    N     = Y.shape[0]\n",
    "    E     = np.zeros(N)\n",
    "    Yh    = np.zeros((N, dim))\n",
    "    Yh[0] = np.dot(xa, Wout)\n",
    "\n",
    "    for i in range(1, N):\n",
    "        # advance one step\n",
    "        xa = step(xa[:N_units], Yh[i-1])\n",
    "        Yh[i] = np.dot(xa, Wout)\n",
    "\n",
    "        # calculate error\n",
    "        error_numerator = np.sum(((Yh[i]-Y[i]))**2)\n",
    "        E[i] = np.sqrt(error_numerator/error_denominator)\n",
    "\n",
    "        if E[i] > threshold:\n",
    "            break\n",
    "            \n",
    "    return i/N_lyap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
